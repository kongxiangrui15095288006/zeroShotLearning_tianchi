
# 零样本图像识别（天池竞赛）

## 题目原文

1. 竞赛题目

   ​	零样本学习是AI识别方法之一。简单来说就是识别从未见过的数据类别，即训练的分类器不仅仅能够识别出训练集中已有的数据类别，还可以对于来自未见过的类别的数据进行区分。这是一个很有用的功能，使得计算机能够具有知识迁移的能力，并无需任何训练数据，很符合现实生活中海量类别的存在形式。本次比赛要求参赛选手提交对测试样本的类别预测值，除官方数据外，不可使用任何外部图片数据进行训练及预训练的模型。主办方提供一个图片数据集，按照类别4：1划分为训练集和测试集，本次比赛训练时禁止使用测试集数据，我们提供一个预训练的类别词向量 和标记的类别属性供选手使用，同时选手可基于外部语料自行训练类别词向量，使用类别的外部关联属性知识库等数据进行辅助训练。本次竞赛主办方有权要求参赛者提交源代码供审查。审查不通过者，取消名次。

2. 数据说明

   * 初赛数据集分Dataset A和Dataset B两部分, 复赛数据集分为Dataset C和Dataset D两部分。训练数据见文件train，测试数据见文件test。

   * 标签见train.txt，文件结构如下：
     a6394b0f513290f4651cc46792e5ac86.jpeg     ZJL1
     每张图片一行，每个字段以Tab隔开，分别表示：图片名     标签 ID  。

   * 标签ID与真实类别英文名称对照，见label_list.txt，文件结构如下：
     ZJL109     gondola
     每个类别一行，每个字段以tab隔开，分别表示：
     标签 ID    标签英文名

   * 预训练的类别词向量文件class_wordembeddings.txt(基于Glove预训练的300维词向量仅供参考)

   * 类别级属性标注，见attributes_per_class.txt，文件结构如下：
     ZJL109      0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0     0

     每张类别一行，每个字段以Tab隔开，分别表示：类别ID     属性标注（顺序同attribute_list.txt，基于众包标注仅供参考）。

   * 属性ID与属性英文名称对照，见attribute_list.txt，文件结构如下：
     1     is animal
     每个属性一行，每个字段以tab隔开，分别表示：属性 ID属性英文名

3. 结果提交说明

   ​	本次竞赛要求选手需将数据集如 Dataset A/B中所有测试样本的标签预测值汇总成一个txt文件如submit.txt进行提交。每行是一个预测结果，应包含图片名称与预测的类别以tab隔开，**格式示例如下**：

   936a67d882c0d5164b2b54d237f0f237.jpeg         ZJL160

4. 评分标准

   ​	本次竞赛的评价标准采用识别正确率。选手模型预测的标签与真实标签一致即为识别正确。设总测试图片数为 N，预测正确的图片数为 M，则识别正确率：Accuracy=M/N。

5. 注意事项

   ​	此赛题禁止参赛者以下行为：

   ​	1）使用外部图片数据/预训练模型进行竞赛；
   ​	2）人工标注/修改评测结果数据；
   ​	3）多账号刷分等。

6. 申明

   ​	1）本比赛所用原始数据来源网络及征集；
   ​	2）本比赛组委会对所有数据进行了标注；
   ​	3）若发现存在侵犯自身合法权益的内容，请及时与大赛组委会组委会AICup2018@zhejianglab.com取得联系，我们将及时处理。

致谢：感谢“AI challenges 全球AI挑战赛组委会”、阿里巴巴达摩院专家在本赛题最终设计中给予的帮助和支持。

## Dependencies

- Python 3
- tensorflow >= 1.2.0
- keras = 2.2.2

## Train and Generate output files

将dataA和dataB的数据解压在当前目录下

main_attribute.ipynb / main_word2vec.ipynb

run all

## 文件分析

* 30个大类（属性）/30个属性英文名——230类标签/230个类别/230个英文物体名称——38221个样本 

  **改进思路：** 由于原始文件给与的30维属性向量为基于人工标注，从此方面来说：

  * 一是利用改进修正手工标准的错误，或者利用数据清理的方法排除特别奇怪的属性（部分实现，有效果）
  * 二是利用大量数据训练神经网络，将数据输入，获得准确的属性值，此部分可能出现累积误差（意为对例如颜色、形状等特征分别预测，此部分的输出作为该类别的属性向量值）（未实现）
  * 三是利用加权的方法，对于标记较为准确的属性加权，对于标记预测不准确的数据降低权重处理（实现，但是由于零样本对验证集与测试集不一致，效果不一致）。

* 300维词向量——230类标签/230个类别/230个英文物体名称——38221个样本 （改进利用词向量的思路）**预训练的类别词向量，文件class_wordembeddings.txt(基于Glove预训练的300维词向量）** 

  **改进思路：** 词向量由官方基于 Glove预训练提供，对于词向量来源于NLP自然语言识别，对此不作深究。

  * 探寻GLOVE的原理，自行改进并训练（未实现）

## 文件说明

文件名 | 属性1 | 对应属性2
:-|:-|:-
trian.txt | 图片文件名(38221张64\*64\*3) | 标签ID(230个id\*1)
label_list.txt | 标签ID(230个id\*1) | 真实物体英文名(230个英文名) 
attributes_per_class.txt | 类别级属性标注标签ID(230) | 属性ID标注(30)
class_wordembeddings.txt | 真实物体英文名(230) | 词向量（300维） 

## 思路总结

以特征提取神经网络为基础，输入样本图片，输出为图片对应标签的属性向量或者词向量，对向量之间的欧式距离或者余弦距离作为loss，进行训练，最终对测试集限定

模型预测输出是相对应的类别属性值，对230个物体（小类）的欧式距离进行对比，输出距离最小的对应标签



## 思路更新

### 9月2日

完成初步能跑通的程序，在GPU上进行模型训练，在windows上进行数据的分析和结果的生成

可改动的地方记录在程序里作为后续修改的思路

此时程序中问题（清理数据）：

* 一是为什么需要将data置为1（原因是将其转化为一个多分类问题）
* 二是需要将分类项加一作为non不存在的分类
* 三是

初始原始优化器RMSprop为SGD

### 9月3日

完成测试，目标天池提交无成绩，重新查看规则， 尝试修改提交文件的格式

进行test0903lr=0.001.h5此模型的测试， 对0：1000训练样本测试正确率为8%，0：10000训练样本呢正确率为3%

**目前可以尝试改进的思路：**

1. 利用题目中关于预训练的类别词向量文件class_wordembeddings.txt(基于Glove预训练的300维词向量仅供参考)此部分原理进行修正
2. 标签数据清洗（网上该baselines原思路是将attributes_per_class.txt中标签ID对应属性的值进行清理，将不到1的置为0、）
3. 基本模型用的是base_model = VGG19可尝试进行修改
4. 关于五个大类中的性格这一类标签参考价值不大，还有关于颜色color类的利用
5. 优化器optimizer 关于SGD 、RMSprop等尝试利用（**尝试后发现还是sgd效果更好**）
6. loss可尝试使用mse，因为在后续中关于标签ID对应时利用的是欧式距离，可以尝试用一下mse均方差(**实现**)
7. 目前为了加速训练一般知识输入10000个样本，迭代次数也并不多，可以尝试多输入样本加快迭代次数来降低loss（**实现**）

### 9月4日

实现提交，分数为0.0019 排名281

训练样本正确率0.14 测试样本正确率0.007

实现了距离检测，损失函数更改为MSE均方差

改正了训练样本输入时顺序，每个种类因为有多个样本，因为如果输入时训练只往一个方向优化使得模型存在偏差

改进了样本输入时的数量，样本数量一定要达到一定数量，否则拟合效果很差

**注：在进行测试时，对系统分样本进行评估**

### 9月5日

实现提交，分数为0.02 排名211

此时训练样本正确率0.34 测试样本正确率0.011， 

实现了数据清理，符合输入标签的形式

训练样本正确率0.84，测试样本正确率0.011，未做提交测试，

问题：过拟合，对未见过的样本识别效果过差

一方面尝试优化模型

一方面利用尝试利用正则化解决过拟合、

**注：分析和测试样本时注意打乱数据来进行检验**

### 9月6日（属性向量）

实现提交，分数0.11 排名 90

此时是将所有训练样本都作为训练集训练的结果，对于训练样本的正确率能达到0.9

改进思路：

1. 从过拟合的角度提高模型泛化性（实现，模型、dropout、正则化）

2. 题目中关于预训练的类别词向量文件class_wordembeddings.txt(基于Glove预训练的300维词向量仅供参考)，利用词向量方法（实现，v2.0）
3. 关于颜色color类的loss较小符合损失下降，loss主要是存在与for 用于什么场景，此部分就算经过大量训练也会难降低loss，同样在加入性格data_5时可能会更乱。（思路：权重设定）
4. base_model改变，实现keras下VGG19和Densenet
5. 零样本识别相关论文寻找改进方法

### 9月14日（词向量）

loss与最终进行验证输出检测是对应

loss采用余弦距离，最终测试也要取得特征向量与便签词向量的余弦距离最小值

**融合问题：** 因为A轮数据测试集中存在训练集中见过的样本，同样存在未见过的样本，因此在此阶段采用了融合的手段，先利用人脸识别中的三元组损失进行是否为存在样本判定，在进行未见过的样本判定

### 9月19日（B轮）

B轮测试集中不包含unseen的样本，直接排除掉样本融合的思路，样本情况也稳定很多

利用词向量效果比属性向量要好

densenet效果比VGG19要好

零样本识别的一个主要问题在于验证集不好确定，无法确认迁移的效果和进行测试

